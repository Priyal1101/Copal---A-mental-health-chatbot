{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee1e839-9ae8-4f94-afbb-9d1338cf7dbc",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b484c12c-b090-460a-a0c5-b67dfe2300e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/u188184/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/u188184/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/u188184/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/u188184/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/u188184/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d520072-89b2-43d6-aa21-36a01b5475cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "718872c4-b040-4c72-9e4c-c868ab2f00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7c563-b260-4094-872a-1e30ead22e1f",
   "metadata": {},
   "source": [
    "### Initializing the Analysers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df46b74d-b2ea-4266-aa3a-e370447f4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Initialize Sentiment Intensity Analyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c213b7a-41a3-487c-842e-f3cf8b462649",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer().lemmatize\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words='english', \n",
    "                             lowercase=True, use_idf=True, norm='l2', \n",
    "                             smooth_idf=True, sublinear_tf=False, \n",
    "                             preprocessor=lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b1b00-cb48-4556-a138-c432ee3945ff",
   "metadata": {},
   "source": [
    "### Intializing Keywords and Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc81ce9a-4d62-4e71-a60c-dc7f3caf3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings = ['Hello! I\\'m an AI chatbot programmed to assist with mental health concerns. How are you feeling today?', \n",
    "             'Hi! I\\'m here to help with your mental health concerns. How can I assist you today?', \n",
    "             'Welcome! I\\'m an AI chatbot designed to support you with your mental health. What\\'s been on your mind lately?']\n",
    "symptom_responses = ['I\\'m sorry to hear that you are feeling {}. Can you tell me more about what\\'s been causing your {}?', \n",
    "                     'It sounds like you are experiencing {}. Would you like to talk more about what\\'s been going on?', \n",
    "                     'Feeling {} can be tough. Would you like to tell me more about what\\'s been happening?']\n",
    "thought_responses = ['I\\'m sorry you are having negative thoughts. Let\\'s challenge them. Can you provide me an example of one negative thought you are having?',\n",
    "                     'I understand you are having pessimistic thoughts. Can you provide me an example?',\n",
    "                     'I\\'m sorry to hear that you feel hopeless. Can you give me an example of a negative thought you\\'ve been having?']\n",
    "behavior_responses = ['I see that you are avoiding certain situations. Let\\'s work on this. Can you give me an example of one situation you have been avoiding?',\n",
    "                      'Procrastination can be tough. Can you tell me more about the tasks you have been putting off?',\n",
    "                      'It sounds like you have been isolating yourself. Would you like to talk more about why that is?']\n",
    "technique_responses = ['Great, let\\'s start with a thought challenging exercise. Here\\'s an example: {}, can you provide me an alternative thought to this?',\n",
    "                       'Behavioral activation can be helpful. Let\\'s set a goal to complete one task today, even if it\\'s small. What do you want to accomplish?',\n",
    "                       'Self-care is important. Let\\'s try a relaxation technique such as deep breathing or progressive muscle relaxation. Would you like to try one now?']\n",
    "unknown_response = ['I\\'m sorry, I don\\'t understand. Can you please rephrase that?', \n",
    "                    'I\\'m not sure I understand what you mean. Can you please clarify?', \n",
    "                    'I\\'m having trouble understanding. Can you please provide more information?']\n",
    "goodbye_responses = ['Goodbye!', 'Take care.', 'Until next time.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0211efe4-2336-43f8-ad33-2ba7bc81f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_keywords = ['hi', 'hello', 'hey', 'hi there', 'hello there']\n",
    "symptom_keywords = ['anxious', 'anxiety', 'stressed', 'stress', 'depressed', 'depression', 'sad', 'lonely']\n",
    "thought_keywords = ['negative', 'pessimistic', 'hopeless', 'helpless', 'overthinking', 'rumination']\n",
    "behavior_keywords = ['avoidance', 'procrastination', 'isolation']\n",
    "technique_keywords = ['thought challenging', 'behavioral activation', 'relaxation', 'self-care']\n",
    "goodbye_keywords = ['exit', 'quit', 'goodbye', 'bye']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bbdd0-2a50-4aea-8cf6-5de388875f9f",
   "metadata": {},
   "source": [
    "### Defining Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4eb8808-1d5c-4664-b21b-906641aef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(token):\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper() #extract the information\n",
    "    tag_dict = {\"J\": wordnet.ADJ, #map\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) #guess noun if unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa4ffb-96b9-408a-99e4-3f9a0732092d",
   "metadata": {},
   "source": [
    "#### Function to process user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4add4c-2454-4f08-be4e-fefe90a8cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(user_input):\n",
    "    # Get sentiment score\n",
    "    sentiment_score = sid.polarity_scores(user_input)['compound']\n",
    "    \n",
    "   # tokenize user input\n",
    "    tokens = nltk.word_tokenize(user_input.lower())\n",
    "    \n",
    "    # lemmatize tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    \n",
    "    # check for keywords\n",
    "    \n",
    "    #initialize variables\n",
    "    greeting = next((keyword for keyword in greeting_keywords if keyword in lemmatized_tokens), False)\n",
    "    symptom = next((keyword for keyword in symptom_keywords if keyword in lemmatized_tokens), False)\n",
    "    thought = next((keyword for keyword in thought_keywords if keyword in lemmatized_tokens), False)\n",
    "    behavior = next((keyword for keyword in behavior_keywords if keyword in lemmatized_tokens), False)\n",
    "    technique = next((keyword for keyword in technique_keywords if keyword in lemmatized_tokens), False)\n",
    "    goodbye = next((keyword for keyword in goodbye_keywords if keyword in lemmatized_tokens), False)\n",
    " \n",
    "    # generate a response based on the keywords\n",
    "    if greeting:\n",
    "        response = random.choice(greetings)\n",
    "    elif symptom:\n",
    "        response = random.choice(symptom_responses).format(symptom)\n",
    "    elif thought:\n",
    "        response = random.choice(thought_responses).format(thought)\n",
    "    elif behavior:\n",
    "        response = random.choice(behavior_responses).format(behavior)\n",
    "    elif technique:\n",
    "        response = random.choice(technique_responses).format(technique)\n",
    "    elif goodbye:\n",
    "        response = random.choice(goodbye_responses)\n",
    "    else:\n",
    "        response = random.choice(unknown_response)\n",
    "    \n",
    "     # reduce dimensions of input data using TSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_data = tsne.fit_transform([sentiment_score])\n",
    "    \n",
    "    # plot data\n",
    "    plt.scatter(reduced_data[0][0], reduced_data[0][1], color='blue')\n",
    "    plt.title('Sentiment Score Visualization')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.show()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266d7b8-28b2-4643-b22f-b198c2e576f8",
   "metadata": {},
   "source": [
    "### Flask Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec64261-597f-4070-ad4f-a56fedd3562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, static_url_path='', static_folder='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f493457f-71c4-44a8-96c2-b920b668888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a route to handle user input and return the sentiment analysis result\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "\n",
    "# Define a function to start the chatbot\n",
    "def chatbot():\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = request.form['user_input']\n",
    "\n",
    "        # Check for exit command\n",
    "        if user_input.lower() in ['exit', 'quit', 'goodbye', 'bye']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Generate a response and print it\n",
    "        response_ = process_input(user_input)\n",
    "        print(response_)\n",
    "        return jsonify({'response': response_})\n",
    "\n",
    "# Define a route to serve the website\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return app.send_static_file('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6aa562-e04f-49c1-a5aa-463f3f74f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d240f4-a9d8-4b99-b206-bc9858e25be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (OpenVINO 2020.3.2 LTS)",
   "language": "python",
   "name": "c003-python_3_lts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
